{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192b0ffc-a2d3-48ef-a713-109707e6f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import statistics\n",
    "import math\n",
    "import sys\n",
    "from pylab import *\n",
    "from math import log\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from generate_data import *\n",
    "from train_models import *\n",
    "from honest_trees import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44adb2a9-7c03-4479-879c-d946cce8f0e6",
   "metadata": {},
   "source": [
    "This notebook is used to run the simulation experiments for fitting sparse linear model with continuous features. The structure of this notebook is as follows: (a) We first fit different tree-based estimators on a linear model with X generated from Uniform([0,1]^d). We then plot the generalisation performance of these different estimators. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db0c966-5f8f-47d1-8787-ee3d436877a0",
   "metadata": {},
   "source": [
    "# Examine Generalisation performance for Sparse Linear Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529a7fdf-69e0-4cce-bef3-0400194dfafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_list(t):\n",
    "    return [log(x,math.e) for x in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2bf38b4-0751-4a57-8ac3-ac562ff2081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_fit_line(x,y):\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    return [m,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd21289e-79a9-4108-bdf3-4c65301a836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = [100,250,500,750,1000,1500,2000,2500]\n",
    "n_test = 500\n",
    "d = 50\n",
    "beta = 1\n",
    "sigma = 0.1\n",
    "sparsity = [10,20]\n",
    "n_avg = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dafb8fe-77cb-4316-b370-cc3d9defb82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize matrix for honest CART \n",
    "honest_CART_scores = []\n",
    "honest_CART_error_bar = []\n",
    "honest_CART_best_fit = []\n",
    "#Initialize matrix for honest CART with CCP \n",
    "#honest_CART_CCP_scores = []\n",
    "#honest_CART_CCP_error_bar = []\n",
    "\n",
    "#Initialize matrix for dishonest CART \n",
    "CART_scores = []\n",
    "CART_error_bar = []\n",
    "CART_best_fit = []\n",
    "\n",
    "#Initialize Matrix for dishonest CART with CCP \n",
    "#CART_CCP_scores = []\n",
    "#CART_CCP_error_bar = []\n",
    "\n",
    "#Initialize Matrix for RF\n",
    "RF_scores = []\n",
    "RF_error_bar = []\n",
    "RF_best_fit = []\n",
    "#Initialize matrix for theoretical lower bound \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d4c3bf-ea50-4824-bb59-4bf527af0e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [07:34<04:32, 90.90s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 41\u001b[0m\n\u001b[0;32m     36\u001b[0m y_test \u001b[38;5;241m=\u001b[39m linear_model(X_test,s,beta,\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m#zero noise since we want to measure ||\\hat{f} - f||_2\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#Fit and predict for all versions of CART\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m honest_CART_MSE,CART_MSE \u001b[38;5;241m=\u001b[39m  train_all_models(X_train,y_train,X_honest,y_honest,X_test,y_test,sigma,k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     42\u001b[0m honest_CART\u001b[38;5;241m.\u001b[39mappend(honest_CART_MSE)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#honest_CART_CCP.append(honest_CART_CCP_MSE)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Disk D\\HCMUS\\Semester 6\\AI\\final\\Group04_DecisionTree_Project\\02_Experiments\\source_code\\Simulations\\train_models.py:50\u001b[0m, in \u001b[0;36mtrain_all_models\u001b[1;34m(X_train, y_train, X_honest, y_honest, X_test, y_test, sigma, k)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_all_models\u001b[39m(X_train,y_train,X_honest,y_honest,X_test,y_test,sigma,k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m---> 50\u001b[0m     honest_CART \u001b[38;5;241m=\u001b[39m  CART(X_train,y_train,X_honest,y_honest,X_test,y_test,honest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     51\u001b[0m     dishonest_CART \u001b[38;5;241m=\u001b[39m CART(X_train,y_train,X_honest,y_honest,X_test,y_test,honest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m#honest_CART_CCP,dishonest_CART_CCP = CART_CCP(X_train,y_train,X_honest,y_honest,X_test,y_test,sigma,k = 5)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Disk D\\HCMUS\\Semester 6\\AI\\final\\Group04_DecisionTree_Project\\02_Experiments\\source_code\\Simulations\\train_models.py:30\u001b[0m, in \u001b[0;36mCART\u001b[1;34m(X_train, y_train, X_honest, y_honest, X_test, y_test, honest)\u001b[0m\n\u001b[0;32m     28\u001b[0m CART \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(min_samples_leaf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     29\u001b[0m CART\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[1;32m---> 30\u001b[0m honest_test_mse \u001b[38;5;241m=\u001b[39m get_honest_test_MSE(CART,X_honest,y_honest,X_test,y_test)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m honest_test_mse\n",
      "File \u001b[1;32mc:\\Disk D\\HCMUS\\Semester 6\\AI\\final\\Group04_DecisionTree_Project\\02_Experiments\\source_code\\Simulations\\..\\honest_trees.py:81\u001b[0m, in \u001b[0;36mget_honest_test_MSE\u001b[1;34m(CART, X_honest, y_honest, X_test, y_test)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_honest_test_MSE\u001b[39m(CART,X_honest,y_honest,X_test,y_test):\n\u001b[1;32m---> 81\u001b[0m     node_id_to_honest_av,node_id_to_honest_count \u001b[38;5;241m=\u001b[39m get_honest_leaf_averages(CART,X_honest,y_honest)\n\u001b[0;32m     82\u001b[0m     test_preds \u001b[38;5;241m=\u001b[39m get_honest_tree_test_preds(CART,X_test,y_test,node_id_to_honest_av,node_id_to_honest_count)\n\u001b[0;32m     83\u001b[0m     test_MSE \u001b[38;5;241m=\u001b[39m mean_squared_error(test_preds,y_test)\n",
      "File \u001b[1;32mc:\\Disk D\\HCMUS\\Semester 6\\AI\\final\\Group04_DecisionTree_Project\\02_Experiments\\source_code\\Simulations\\..\\honest_trees.py:57\u001b[0m, in \u001b[0;36mget_honest_leaf_averages\u001b[1;34m(CART, X_honest, y_honest)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m all_node_ids:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m X_honest_node_ids:\n\u001b[1;32m---> 57\u001b[0m         honest_sample_ids_at_node \u001b[38;5;241m=\u001b[39m [sample_id \u001b[38;5;28;01mfor\u001b[39;00m sample_id,decision_path \u001b[38;5;129;01min\u001b[39;00m X_honest_decsion_paths\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m decision_path]\n\u001b[0;32m     58\u001b[0m         node_id_to_honest_av[node_id] \u001b[38;5;241m=\u001b[39m y_honest[honest_sample_ids_at_node]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     59\u001b[0m         node_id_to_honest_count[node_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(honest_sample_ids_at_node)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#This cell's code is used to fit and predict for on linear model varying across the number of training samples/sparsity \n",
    "for s in sparsity: \n",
    "    honest_CART_s = []\n",
    "    honest_CART_s_error_bar = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    #honest_CART_CCP_s = []\n",
    "    #honest_CART_CCP_s_error_bar = []\n",
    "    CART_s = []\n",
    "    CART_s_error_bar = []\n",
    "  \n",
    "    \n",
    "    #CART_CCP_s = []\n",
    "    #CART_CCP_s_error_bar = []\n",
    "    \n",
    "    RF_s = []\n",
    "    RF_s_error_bar = []\n",
    "\n",
    "    \n",
    "    for n in tqdm(n_train):\n",
    "        honest_CART = []\n",
    "        #honest_CART_CCP = []\n",
    "        CART = []\n",
    "        #CART_CCP = []\n",
    "        RF = []\n",
    "        for j in range(n_avg):\n",
    "            #Create data to fit models \n",
    "            X_train = sample_uniform_X(n,d)\n",
    "            X_honest = sample_uniform_X(n,d)\n",
    "            X_test = sample_uniform_X(n_test,d)\n",
    "            \n",
    "            \n",
    "            y_train = linear_model(X_train,s,beta,sigma)\n",
    "            y_honest = linear_model(X_honest,s,beta,sigma)\n",
    "            y_test = linear_model(X_test,s,beta,0) #zero noise since we want to measure ||\\hat{f} - f||_2\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Fit and predict for all versions of CART\n",
    "            honest_CART_MSE,CART_MSE =  train_all_models(X_train,y_train,X_honest,y_honest,X_test,y_test,sigma,k = 5)\n",
    "            honest_CART.append(honest_CART_MSE)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #honest_CART_CCP.append(honest_CART_CCP_MSE)\n",
    "            CART.append(CART_MSE)\n",
    "            #CART_CCP.append(CART_CCP_MSE)\n",
    "            \n",
    "            #Fit and predict for RF\n",
    "            rf = RandomForestRegressor(n_estimators = 100,max_features = 0.33)\n",
    "            rf.fit(X_train,y_train)\n",
    "            rf_preds = rf.predict(X_test)\n",
    "            RF.append(mean_squared_error(y_test,rf_preds))\n",
    "            \n",
    "            \n",
    "            \n",
    "        #Store Performance in matrix\n",
    "        honest_CART_s.append(statistics.mean(honest_CART))\n",
    "        honest_CART_s_error_bar.append(statistics.stdev(honest_CART))\n",
    "        \n",
    "        #honest_CART_CCP_s.append(statistics.mean(honest_CART_CCP))\n",
    "        #honest_CART_CCP_s_error_bar.append(statistics.stdev(honest_CART_CCP))\n",
    "        \n",
    "        CART_s.append(statistics.mean(CART))\n",
    "        CART_s_error_bar.append(statistics.stdev(CART))\n",
    "        \n",
    "        #CART_CCP_s.append(statistics.mean(CART_CCP))\n",
    "        #CART_CCP_s_error_bar.append(statistics.stdev(CART_CCP))\n",
    "        \n",
    "        RF_s.append(statistics.mean(RF))\n",
    "        RF_s_error_bar.append(statistics.stdev(RF))\n",
    "        \n",
    "\n",
    "    \n",
    "    #save results \n",
    "    honest_CART_scores.append(honest_CART_s)\n",
    "    #honest_CART_CCP_scores.append(honest_CART_CCP_s)\n",
    "    CART_scores.append(CART_s)\n",
    "    #CART_CCP_scores.append(CART_CCP_s)\n",
    "    RF_scores.append(RF_s)\n",
    "    \n",
    "    \n",
    "    honest_CART_error_bar.append(honest_CART_s_error_bar)\n",
    "    #honest_CART_CCP_error_bar.append(honest_CART_CCP_s_error_bar)\n",
    "    CART_error_bar.append(CART_s_error_bar)\n",
    "    #CART_CCP_error_bar.append(CART_CCP_s_error_bar) \n",
    "    RF_error_bar.append(RF_s_error_bar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124e21d-7b98-4789-9fe6-463319715b9d",
   "metadata": {},
   "source": [
    "# Save Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb50bdc-5f05-4f9c-91e9-10d984dd8742",
   "metadata": {},
   "outputs": [],
   "source": [
    "honest_CART_results = (honest_CART_scores,honest_CART_error_bar)\n",
    "with open('results/linear_cts/honestCART.pkl','wb') as f:\n",
    "    pickle.dump(honest_CART_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bf5ec5-caa5-4d0b-ac2f-09e91bbd7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CART_results = (CART_scores,CART_error_bar)\n",
    "with open('results/linear_cts/CART.pkl','wb') as f:\n",
    "    pickle.dump(CART_results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d7803-a921-49d2-ba01-ced6b43e1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_results = (RF_scores,RF_error_bar)\n",
    "with open('results/linear_cts/RF.pkl','wb') as f:\n",
    "    pickle.dump(RF_results,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7332674-4ba8-44db-9699-faf02abbe9c8",
   "metadata": {},
   "source": [
    "# Load Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa8f944-5b98-483b-bb6f-22525667f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('results/linear_cts/honestCART.pkl','rb') as f:\n",
    "    honest_CART_scores,honest_CART_error_bar = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0e153-4678-4bd0-a27f-9bd4b5ba9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('results/linear_cts/CART.pkl','rb') as f:\n",
    "    CART_scores,CART_error_bar = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e09cc1-a8f8-408c-9156-15d9fc48f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('results/linear_cts/RF.pkl','rb') as f:\n",
    "    RF_scores,RF_error_bar = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4843dc3-4596-4d87-aa2f-f82018bc2e18",
   "metadata": {},
   "source": [
    "# Best-fit line Slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43993c49-e3e2-4e9f-bdca-55fce4edee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i,s) in enumerate(sparsity):\n",
    "    honest_CART_best_fit.append(get_best_fit_line(log_list(n_train),log_list(honest_CART_scores[i])))\n",
    "    CART_best_fit.append(get_best_fit_line(log_list(n_train),log_list(CART_scores[i])))\n",
    "    RF_best_fit.append(get_best_fit_line(log_list(n_train),log_list(RF_scores[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382f4fe-f018-4e7c-ac5f-fb76b714e87d",
   "metadata": {},
   "source": [
    "# Plot Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38575e5-dd95-4dae-94c2-17a7c0eb1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "# Set global plotting parameters\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['grid.linewidth'] = 2.5\n",
    "mpl.rcParams['legend.fontsize'] = 20\n",
    "pylab.rcParams['xtick.major.pad'] = 5\n",
    "pylab.rcParams['ytick.major.pad'] = 5\n",
    "mpl.rcParams[\"figure.figsize\"] = [8, 6]\n",
    "mpl.rcParams['savefig.transparent'] = True\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['figure.edgecolor'] = 'black'\n",
    "# plt.rcParams['patch.edgecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "# plt.rcParams['grid.color'] = 'black'\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "label_size = 25\n",
    "mpl.rcParams['xtick.labelsize'] = label_size \n",
    "mpl.rcParams['ytick.labelsize'] = label_size \n",
    "mpl.rcParams['axes.labelsize'] = label_size\n",
    "mpl.rcParams['axes.titlesize'] = label_size\n",
    "mpl.rcParams['figure.titlesize'] = label_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832de4f-25af-42e8-af3d-fed02ca86f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1cf43f3ee90>,\n",
       "  <matplotlib.axis.YTick at 0x1cf44f8d450>,\n",
       "  <matplotlib.axis.YTick at 0x1cf44f8dbd0>,\n",
       "  <matplotlib.axis.YTick at 0x1cf44f8e350>],\n",
       " [])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_lower_bound_fig,linear_lower_bound_axs = plt.subplots(1,2,figsize = (20,8),sharex = True,sharey = True)\n",
    "\n",
    "\n",
    "#Plot Performance for different models \n",
    "\n",
    "# s = 10\n",
    "linear_lower_bound_axs[0].errorbar(n_train,honest_CART_scores[0],yerr = honest_CART_error_bar[0],fmt = '^',label = 'honest CART',color = 'green')\n",
    "linear_lower_bound_axs[0].errorbar(n_train,pow(math.e,honest_CART_best_fit[0][0]*np.array(log_list(n_train))+honest_CART_best_fit[0][1]),linestyle = 'dashed',label = 'slope = ' +str(honest_CART_best_fit[0][0])[:5],color = 'green')\n",
    "\n",
    "linear_lower_bound_axs[0].errorbar(n_train,CART_scores[0],yerr = CART_error_bar[0],fmt = 'x',label = 'CART',color = 'red')\n",
    "linear_lower_bound_axs[0].errorbar(n_train,pow(math.e,CART_best_fit[0][0]*np.array(log_list(n_train))+CART_best_fit[0][1]),linestyle = 'dashed',label = 'slope = ' + str(CART_best_fit[0][0])[:5],color = 'red')\n",
    "\n",
    "\n",
    "linear_lower_bound_axs[0].errorbar(n_train,RF_scores[0],yerr = RF_error_bar[0],fmt = 'o',label = 'RF',color = 'blue')\n",
    "linear_lower_bound_axs[0].errorbar(n_train,pow(math.e,RF_best_fit[0][0]*np.array(log_list(n_train))+RF_best_fit[0][1]),linestyle = 'dashed',label = 'slope = ' + str(RF_best_fit[0][0])[:5],color = 'blue')\n",
    "\n",
    "\n",
    "\n",
    "# s = 20 \n",
    "linear_lower_bound_axs[1].errorbar(n_train,honest_CART_scores[1],yerr = honest_CART_error_bar[0],fmt = '^',label = 'honest CART',color = 'green')\n",
    "linear_lower_bound_axs[1].errorbar(n_train,pow(math.e,honest_CART_best_fit[1][0]*np.array(log_list(n_train))+honest_CART_best_fit[1][1]),linestyle = 'dashed',label = 'slope = ' +str(honest_CART_best_fit[1][0])[:5],color = 'green')\n",
    "\n",
    "linear_lower_bound_axs[1].errorbar(n_train,CART_scores[1],yerr = CART_error_bar[1],fmt = 'x',label = 'CART',color = 'red')\n",
    "linear_lower_bound_axs[1].errorbar(n_train,pow(math.e,CART_best_fit[1][0]*np.array(log_list(n_train))+CART_best_fit[1][1]),linestyle = 'dashed',label = 'slope = ' + str(CART_best_fit[1][0])[:5],color = 'red')\n",
    "\n",
    "\n",
    "linear_lower_bound_axs[1].errorbar(n_train,RF_scores[1],yerr = RF_error_bar[1],fmt = 'o',label = 'RF',color = 'blue')\n",
    "linear_lower_bound_axs[1].errorbar(n_train,pow(math.e,RF_best_fit[1][0]*np.array(log_list(n_train))+RF_best_fit[1][1]),linestyle = 'dashed',label = 'slope = ' +str(RF_best_fit[1][0])[:5],color = 'blue')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "linear_lower_bound_axs[0].legend(loc = 'best')\n",
    "linear_lower_bound_axs[1].legend(loc = 'best')\n",
    "\n",
    "linear_lower_bound_axs[0].text(500.0, 3.45, 's=10',\n",
    "      fontsize=16, fontweight='bold', va='top')\n",
    "linear_lower_bound_axs[1].text(500.0, 3.45, 's=20',\n",
    "      fontsize=16, fontweight='bold', va='top')\n",
    "linear_lower_bound_axs[0].set_ylabel('MSE',fontsize = 25)\n",
    "#linear_lower_bound_axs[1].set_ylabel('MSE',fontsize = 18)\n",
    "\n",
    "linear_lower_bound_axs[0].set_xlabel('Number of Samples n',fontsize = 25)\n",
    "linear_lower_bound_axs[1].set_xlabel('Number of Samples n',fontsize = 25)\n",
    "\n",
    "linear_lower_bound_axs[0].set_yscale('log')\n",
    "linear_lower_bound_axs[1].set_yscale('log')\n",
    "linear_lower_bound_axs[0].set_xscale('log')\n",
    "linear_lower_bound_axs[1].set_xscale('log')\n",
    "\n",
    "linear_lower_bound_axs[0].grid()\n",
    "linear_lower_bound_axs[1].grid()\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout(pad=0.4,w_pad=0.5, h_pad=1.5)\n",
    "\n",
    "labels = [r'$2 \\times \\mathregular{10^{-1}}$', r'$5 \\times \\mathregular{10^{-1}}$', r'$\\mathregular{10^{0}}$',r'$3 \\times \\mathregular{10^{0}}$']\n",
    "ytick = [0.2,0.5,1.0,3.0]\n",
    "#plt.xticks(n_train, labels, rotation='vertical')\n",
    "\n",
    "\n",
    "#linear_lower_bound_axs[0].set_yticks([0.1, 0.5, 1.0,3.0])\n",
    "plt.yticks(ytick,labels)\n",
    "#linear_lower_bound_axs[0].get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "#linear_lower_bound_axs[0].set_ylim(0.1, 3.0);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f47e6-fa58-4a20-aa02-a0b0d31a8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_lower_bound_fig.savefig('figures/linear_cts.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
